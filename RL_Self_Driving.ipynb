{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac0a74b",
   "metadata": {},
   "source": [
    "#### We are gonna use the racing car environmet so the idea is trying to get a car to drive around a randomly generated race tack\n",
    "\n",
    "### Action Space\n",
    "\n",
    "###### If continuous there are 3 actions :\n",
    "\n",
    "0: steering, -1 is full left, +1 is full right\n",
    "1: gas\n",
    "2: breaking\n",
    "\n",
    "###### If discrete there are 5 actions:\n",
    "\n",
    "0: do nothing\n",
    "1: steer left\n",
    "2: steer right\n",
    "3: gas\n",
    "4: brake\n",
    "\n",
    "###  Observation Space\n",
    "\n",
    "A top-down 96x96 RGB image of the car and race track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9aa4b",
   "metadata": {},
   "source": [
    "###  1- Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35a6beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a1e3c",
   "metadata": {},
   "source": [
    "###  2- Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e307bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CarRacing-v2'\n",
    "env = gym.make(env_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00014185",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb63a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space  # check that are 3 values from 0 t0 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8623af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render() # reder allow render the actual enviroment in which we are working on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dabe76",
   "metadata": {},
   "source": [
    "###### test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b712d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):  # we're gonna check 5 times\n",
    "    state = env.reset() # reset the env so we have a initial set of observations \n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render() # visualise the enviroment \n",
    "        action = env.action_space.sample() # take an action randomicaly\n",
    "        n_state, reward, done, info,_ = env.step(action) # apply an action to the enviroment \n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close() # close down the render frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca372f5",
   "metadata": {},
   "source": [
    "###  3- Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7707b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate our environment\n",
    "env = gym.make(env_name) \n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac1e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','logs')\n",
    "model = PPO('CnnPolicy',env, verbose=1,tensorboard_log=log_path)  # create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a32974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=10000) # let's train for 10000 steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa4065d",
   "metadata": {},
   "source": [
    "###  4- Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01d97606",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training','Saved Models','PPO_SelfDrive_model')\n",
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fd5a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # delete the model to load and che"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d426af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model=PPO.load(PPO_Path,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f223a8",
   "metadata": {},
   "source": [
    "###  5- Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6caafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name, render_mode=\"human\")\n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True) # render is to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8822e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08256a0",
   "metadata": {},
   "source": [
    "Test the self driving with a model trained 428000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path_2 = os.path.join('Training','Saved Models','PPO_428k_Driving_model')\n",
    "model=PPO.load(PPO_Path_2,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(env_name, render_mode=\"human\")\n",
    "evaluate_policy(model, env, n_eval_episodes=10, render=True) # render is to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead to evaluate with a encapsulate function as before let's create a evaluation where we use the trained agent\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):  \n",
    "    observations,_ = env.reset() \n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render() \n",
    "        action,_ = model.predict(observations) # here for the action we use the prediction of our trained model\n",
    "        observations, reward, done, info,_ = env.step(action) \n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
